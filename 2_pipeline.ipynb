{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# function to train-test-split data and treat it\n",
    "\n",
    "def split_and_treat_data(X, y, encode_cats=True, save_encoder=False, scale_nums=True, save_scaler=False, randomstate=None):\n",
    "    # splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=randomstate)\n",
    "\n",
    "    # transforming numericals\n",
    "    if scale_nums:\n",
    "        transformer = MinMaxScaler().fit(X_train.select_dtypes(np.number))\n",
    "\n",
    "        cols_nums = X.select_dtypes(np.number).columns\n",
    "        \n",
    "        X_train_norm = pd.DataFrame(transformer.transform(X_train.select_dtypes(np.number)), columns=cols_nums)\n",
    "        X_test_norm = pd.DataFrame(transformer.transform(X_test.select_dtypes(np.number)), columns=cols_nums)\n",
    "    else:\n",
    "        X_train_norm = X_train.select_dtypes(np.number)\n",
    "        X_test_norm = X_test.select_dtypes(np.number)\n",
    "\n",
    "    if save_scaler:\n",
    "        pickle.dump(transformer, open('scaler.sav', 'wb'))\n",
    "\n",
    "    # encoding categoricals\n",
    "    if encode_cats:\n",
    "        encoder = OneHotEncoder(drop='first', handle_unknown='ignore').fit(pd.DataFrame(X_train.select_dtypes(object)))\n",
    "\n",
    "        encoded_train = encoder.transform(pd.DataFrame(X_train.select_dtypes(object))).toarray()\n",
    "        encoded_test = encoder.transform(pd.DataFrame(X_test.select_dtypes(object))).toarray()\n",
    "\n",
    "        cols_cats = encoder.get_feature_names_out(input_features=X_train.select_dtypes(object).columns)\n",
    "\n",
    "        onehot_encoded_cats_train = pd.DataFrame(encoded_train, columns=cols_cats).astype(object)\n",
    "        onehot_encoded_cats_test = pd.DataFrame(encoded_test, columns=cols_cats).astype(object)\n",
    "    else:\n",
    "        onehot_encoded_cats_train = X_train.select_dtypes(object)\n",
    "        onehot_encoded_cats_test = X_test.select_dtypes(object)\n",
    "\n",
    "    if save_encoder:\n",
    "        pickle.dump(encoder, open('encoder.sav', 'wb'))\n",
    "\n",
    "    # concat cats + nums back together\n",
    "    X_train_treated = pd.concat([X_train_norm, onehot_encoded_cats_train], axis=1)\n",
    "    X_test_treated = pd.concat([X_test_norm, onehot_encoded_cats_test], axis=1)\n",
    "\n",
    "    return X_train_treated.reset_index(drop=True), X_test_treated, y_train.reset_index(drop=True), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# function for manually resampling to a size between a majority and a minority (only 2 targets possible)\n",
    "\n",
    "def resample_treated(X_train_treated, X_test_treated, y_train, y_test, resample_size, show_dists=False):\n",
    "    # concat back input and target of training data\n",
    "    train_data = pd.concat([X_train_treated, y_train], axis=1)\n",
    "\n",
    "    # split majority/minority \n",
    "    mayority = pd.Series(y_train).index[0]\n",
    "    category_0 = train_data[train_data[y_train.name] == mayority]\n",
    "    category_1 = train_data[train_data[y_train.name] != mayority]\n",
    "\n",
    "    # resample the classes\n",
    "    category_0_undersampled = resample(category_0, replace=False, n_samples = resample_size)\n",
    "    category_1_oversampled = resample(category_1, replace=True, n_samples = resample_size)\n",
    "\n",
    "    # concat majority/minority back together\n",
    "    train_data = pd.concat([category_0_undersampled, category_1_oversampled], axis=0)\n",
    "\n",
    "    # split input and target\n",
    "    X_train_resampled = train_data.drop([y_train.name], axis=1)\n",
    "    y_train_resampled = train_data[y_train.name]\n",
    "\n",
    "    # show information if flag is set to True\n",
    "    if show_dists:\n",
    "        counts = y_train.value_counts()\n",
    "        print(f'Resampled from: {counts[0]}/{counts()[1]} to {resample_size}/{resample_size}')\n",
    "\n",
    "    return X_train_resampled, X_test_treated, y_train_resampled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# function for automatic resampling using SMOTE and RandomUnderSampler (by default ending up with size of 0.5 of mayority)\n",
    "\n",
    "def smote_rnd_treated(X_train_treated, X_test_treated, y_train, y_test, size=100, show_dists=False):\n",
    "    # strategy is fraction of y_train-mayority\n",
    "    mayority = pd.Series(y_train).value_counts()[0]\n",
    "    strat = size/mayority\n",
    "    before = y_train.value_counts()\n",
    "\n",
    "    X_train_treated,y_train = SMOTE(sampling_strategy=strat).fit_resample(X_train_treated, y_train)\n",
    "    if strat < 1.0:\n",
    "        X_train_treated,y_train = RandomUnderSampler(sampling_strategy=1.0).fit_resample(X_train_treated,y_train)\n",
    "\n",
    "    after = y_train.value_counts()\n",
    "\n",
    "    # show information if flag is set to True\n",
    "    if show_dists:\n",
    "        print(f'Resampled from: {before[0]}/{before()[1]} to {after[0]}/{after[1]}')\n",
    "\n",
    "    return X_train_treated, X_test_treated, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# function to fit and evaluate a model\n",
    "\n",
    "def build_eval_model(X_train_treated, X_test_treated, y_train, y_test, model, save_model=False, decimals=5):\n",
    "    # predict y_test\n",
    "    model = model.fit(X_train_treated, y_train)\n",
    "    pred = model.predict(X_test_treated)\n",
    "    \n",
    "    acc = round(model.score(X_test_treated, y_test),decimals)\n",
    "    prec = round(precision_score(y_test, pred),decimals)\n",
    "    recall = round(recall_score(y_test, pred),decimals)\n",
    "    f1 = round(f1_score(y_test, pred),decimals)\n",
    "\n",
    "    # evaluate predictions\n",
    "    conf = confusion_matrix(y_test, pred)\n",
    "    f_p = float(conf[0][1])\n",
    "    t_p = float(conf[1][1])\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    if save_model:\n",
    "        model_name = str(model).split('(')[0]\n",
    "        pickle.dump(model, open(f'{model_name}.sav', 'wb'))\n",
    "\n",
    "    print(\"accuracy:\", acc, \"  precision:\", prec, \"  recall:\", recall, \"  f1:\", f1, \"\\n\")\n",
    "    print(pd.DataFrame(conf), end='')\n",
    "\n",
    "    # return scores-dict\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1, \"false_positives\": f_p, \"true_positives\": t_p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# pipeline function to combine multiple inputs and models\n",
    "\n",
    "def pipeline(\n",
    "    categoricals, \n",
    "    numericals_path:str, \n",
    "    y, \n",
    "    models, \n",
    "    save_models=False, \n",
    "    include_cats=True, \n",
    "    encode_cats=True, \n",
    "    save_encoder=False, \n",
    "    scale_nums=True, \n",
    "    save_scaler=False, \n",
    "    save_scores=False, \n",
    "    sampling=None, \n",
    "    size=1, \n",
    "    may_val=1, min_val=0):\n",
    "\n",
    "    scores = {}\n",
    "    for model_name, model in models:\n",
    "        # set selection string\n",
    "        selection = numericals_path.split('_nums')[0]\n",
    "        selection = selection.split('lab/')[1]\n",
    "        if include_cats:\n",
    "            selection += '_with_cats'\n",
    "\n",
    "        print('#############   Model |', model_name, '  #############   Data |', selection, '  #############\\n')\n",
    "\n",
    "        # set X data\n",
    "        if include_cats:\n",
    "            X = pd.concat([categoricals, pd.read_csv(numericals_path)], axis=1)\n",
    "        else:\n",
    "            X = pd.read_csv(numericals_path)\n",
    "        a,b,c,d = split_and_treat_data(X, y, encode_cats=encode_cats, save_encoder=save_encoder, scale_nums=scale_nums, save_scaler=save_scaler)\n",
    "\n",
    "        # evaluate sampling-flag\n",
    "        if sampling == 'resample':\n",
    "            a,b,c2,d = resample_treated(a,b,c,d, size)\n",
    "        elif sampling == 'smote_rnd':\n",
    "            a,b,c2,d = smote_rnd_treated(a,b,c,d, size)\n",
    "        else:\n",
    "            c2 = c\n",
    "        \n",
    "        # create scores-dict and add a sampling info\n",
    "        model_id = model_name.replace(' ','')\n",
    "        identif = f'{model_id}_{selection}'\n",
    "        scores[identif] = build_eval_model(a,b,c2,d, model, save_model=save_models)\n",
    "        scores[identif]['resampling'] = sampling\n",
    "\n",
    "        # print log sampling and set final save_string\n",
    "        if sampling:\n",
    "            file_name = f'scores/scores_{len(scores)}models_features_{selection}_{sampling}_{size}.json'\n",
    "            print(f'\\t\\tTraining data resampled from: {c.value_counts()[0]}/{c.value_counts()[1]} to {c2.value_counts()[0]}/{c2.value_counts()[1]}\\n')\n",
    "        else:\n",
    "            file_name = f'scores/scores_{len(scores)}models_features_{selection}_{c.value_counts()[0]}_{c.value_counts()[1]}.json'\n",
    "            print(f'\\t\\tTraining data sample sizes: {c.value_counts()[0]}/{c.value_counts()[1]}')\n",
    "\n",
    "    # save if flag is set with last set file name\n",
    "    if save_scores:\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(scores, f, indent=4)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data with different features\n",
    "\n",
    "cats = pd.read_csv('files_for_lab/categorical.csv').astype(object)\n",
    "targets = pd.read_csv('files_for_lab/target.csv')\n",
    "\n",
    "# create dict for X for different numericals, set target y\n",
    "y = targets['TARGET_B']\n",
    "\n",
    "num_paths = []\n",
    "methods = ['kbest', 'rfe', 'var', 'pca', 'all']\n",
    "\n",
    "# read in feature selected data\n",
    "for method in methods:\n",
    "    num_paths.append(f'files_for_lab/{method}_nums.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############   Model | Logistic Regression   #############   Data | kbest_with_cats   #############\n",
      "\n",
      "accuracy: 0.61791   precision: 0.06974   recall: 0.50797   f1: 0.12264 \n",
      "\n",
      "       0     1\n",
      "0  14102  8497\n",
      "1    617   637\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | kbest_with_cats   #############\n",
      "\n",
      "accuracy: 0.45919   precision: 0.05759   recall: 0.60447   f1: 0.10516 \n",
      "\n",
      "       0      1\n",
      "0  10195  12404\n",
      "1    496    758\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | kbest_with_cats   #############\n",
      "\n",
      "accuracy: 0.84715   precision: 0.09458   recall: 0.22249   f1: 0.13273 \n",
      "\n",
      "       0     1\n",
      "0  19928  2671\n",
      "1    975   279\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | kbest_with_cats   #############\n",
      "\n",
      "accuracy: 0.88379   precision: 0.07598   recall: 0.10845   f1: 0.08936 \n",
      "\n",
      "       0     1\n",
      "0  20945  1654\n",
      "1   1118   136\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | kbest   #############\n",
      "\n",
      "accuracy: 0.59762   precision: 0.0714   recall: 0.55423   f1: 0.1265 \n",
      "\n",
      "       0     1\n",
      "0  13560  9039\n",
      "1    559   695\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | kbest   #############\n",
      "\n",
      "accuracy: 0.71907   precision: 0.05923   recall: 0.29187   f1: 0.09848 \n",
      "\n",
      "       0     1\n",
      "0  16786  5813\n",
      "1    888   366\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | kbest   #############\n",
      "\n",
      "accuracy: 0.75974   precision: 0.06219   recall: 0.25359   f1: 0.09989 \n",
      "\n",
      "       0     1\n",
      "0  17804  4795\n",
      "1    936   318\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | kbest   #############\n",
      "\n",
      "accuracy: 0.89645   precision: 0.07183   recall: 0.08134   f1: 0.07629 \n",
      "\n",
      "       0     1\n",
      "0  21281  1318\n",
      "1   1152   102\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | rfe_with_cats   #############\n",
      "\n",
      "accuracy: 0.61741   precision: 0.06757   recall: 0.49043   f1: 0.11877 \n",
      "\n",
      "       0     1\n",
      "0  14112  8487\n",
      "1    639   615\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | rfe_with_cats   #############\n",
      "\n",
      "accuracy: 0.47734   precision: 0.05746   recall: 0.58054   f1: 0.10458 \n",
      "\n",
      "       0      1\n",
      "0  10658  11941\n",
      "1    526    728\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | rfe_with_cats   #############\n",
      "\n",
      "accuracy: 0.7101   precision: 0.06069   recall: 0.3118   f1: 0.1016 \n",
      "\n",
      "       0     1\n",
      "0  16547  6052\n",
      "1    863   391\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | rfe_with_cats   #############\n",
      "\n",
      "accuracy: 0.88438   precision: 0.07514   recall: 0.10606   f1: 0.08796 \n",
      "\n",
      "       0     1\n",
      "0  20962  1637\n",
      "1   1121   133\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | rfe   #############\n",
      "\n",
      "accuracy: 0.57871   precision: 0.06671   recall: 0.53987   f1: 0.11874 \n",
      "\n",
      "       0     1\n",
      "0  13127  9472\n",
      "1    577   677\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | rfe   #############\n",
      "\n",
      "accuracy: 0.73521   precision: 0.0555   recall: 0.25199   f1: 0.09096 \n",
      "\n",
      "       0     1\n",
      "0  17221  5378\n",
      "1    938   316\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | rfe   #############\n",
      "\n",
      "accuracy: 0.72746   precision: 0.07431   recall: 0.36523   f1: 0.1235 \n",
      "\n",
      "       0     1\n",
      "0  16894  5705\n",
      "1    796   458\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | rfe   #############\n",
      "\n",
      "accuracy: 0.88547   precision: 0.05535   recall: 0.07337   f1: 0.0631 \n",
      "\n",
      "       0     1\n",
      "0  21029  1570\n",
      "1   1162    92\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | var_with_cats   #############\n",
      "\n",
      "accuracy: 0.6138   precision: 0.06956   recall: 0.51276   f1: 0.1225 \n",
      "\n",
      "       0     1\n",
      "0  13998  8601\n",
      "1    611   643\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | var_with_cats   #############\n",
      "\n",
      "accuracy: 0.43739   precision: 0.05728   recall: 0.62759   f1: 0.10498 \n",
      "\n",
      "      0      1\n",
      "0  9646  12953\n",
      "1   467    787\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | var_with_cats   #############\n",
      "\n",
      "accuracy: 0.84513   precision: 0.09415   recall: 0.22568   f1: 0.13286 \n",
      "\n",
      "       0     1\n",
      "0  19876  2723\n",
      "1    971   283\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | var_with_cats   #############\n",
      "\n",
      "accuracy: 0.88358   precision: 0.07624   recall: 0.10925   f1: 0.08981 \n",
      "\n",
      "       0     1\n",
      "0  20939  1660\n",
      "1   1117   137\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | var   #############\n",
      "\n",
      "accuracy: 0.61439   precision: 0.0705   recall: 0.51994   f1: 0.12417 \n",
      "\n",
      "       0     1\n",
      "0  14003  8596\n",
      "1    602   652\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | var   #############\n",
      "\n",
      "accuracy: 0.73605   precision: 0.05896   recall: 0.26874   f1: 0.0967 \n",
      "\n",
      "       0     1\n",
      "0  17220  5379\n",
      "1    917   337\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | var   #############\n",
      "\n",
      "accuracy: 0.84757   precision: 0.09462   recall: 0.22169   f1: 0.13263 \n",
      "\n",
      "       0     1\n",
      "0  19939  2660\n",
      "1    976   278\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | var   #############\n",
      "\n",
      "accuracy: 0.8339   precision: 0.0821   recall: 0.21212   f1: 0.11838 \n",
      "\n",
      "       0     1\n",
      "0  19625  2974\n",
      "1    988   266\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | pca_with_cats   #############\n",
      "\n",
      "accuracy: 0.62097   precision: 0.06724   recall: 0.48246   f1: 0.11804 \n",
      "\n",
      "       0     1\n",
      "0  14207  8392\n",
      "1    649   605\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | pca_with_cats   #############\n",
      "\n",
      "accuracy: 0.45525   precision: 0.05705   recall: 0.60287   f1: 0.10423 \n",
      "\n",
      "       0      1\n",
      "0  10103  12496\n",
      "1    498    756\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | pca_with_cats   #############\n",
      "\n",
      "accuracy: 0.82899   precision: 0.08541   recall: 0.23206   f1: 0.12487 \n",
      "\n",
      "       0     1\n",
      "0  19483  3116\n",
      "1    963   291\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | pca_with_cats   #############\n",
      "\n",
      "accuracy: 0.89779   precision: 0.07835   recall: 0.08772   f1: 0.08277 \n",
      "\n",
      "       0     1\n",
      "0  21305  1294\n",
      "1   1144   110\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | pca   #############\n",
      "\n",
      "accuracy: 0.51524   precision: 0.05337   recall: 0.49123   f1: 0.09629 \n",
      "\n",
      "       0      1\n",
      "0  11674  10925\n",
      "1    638    616\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | pca   #############\n",
      "\n",
      "accuracy: 0.70645   precision: 0.05234   recall: 0.26794   f1: 0.08757 \n",
      "\n",
      "       0     1\n",
      "0  16515  6084\n",
      "1    918   336\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | pca   #############\n",
      "\n",
      "accuracy: 0.39639   precision: 0.05286   recall: 0.61962   f1: 0.09742 \n",
      "\n",
      "      0      1\n",
      "0  8678  13921\n",
      "1   477    777\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | pca   #############\n",
      "\n",
      "accuracy: 0.56815   precision: 0.05244   recall: 0.42265   f1: 0.0933 \n",
      "\n",
      "       0     1\n",
      "0  13022  9577\n",
      "1    724   530\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | all_with_cats   #############\n",
      "\n",
      "accuracy: 0.619   precision: 0.06613   recall: 0.47608   f1: 0.11613 \n",
      "\n",
      "       0     1\n",
      "0  14168  8431\n",
      "1    657   597\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | all_with_cats   #############\n",
      "\n",
      "accuracy: 0.36863   precision: 0.05778   recall: 0.7193   f1: 0.10697 \n",
      "\n",
      "      0      1\n",
      "0  7891  14708\n",
      "1   352    902\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | all_with_cats   #############\n",
      "\n",
      "accuracy: 0.84757   precision: 0.09462   recall: 0.22169   f1: 0.13263 \n",
      "\n",
      "       0     1\n",
      "0  19939  2660\n",
      "1    976   278\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | all_with_cats   #############\n",
      "\n",
      "accuracy: 0.91154   precision: 0.08121   recall: 0.06619   f1: 0.07293 \n",
      "\n",
      "       0    1\n",
      "0  21660  939\n",
      "1   1171   83\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Logistic Regression   #############   Data | all   #############\n",
      "\n",
      "accuracy: 0.59158   precision: 0.06703   recall: 0.52392   f1: 0.11885 \n",
      "\n",
      "       0     1\n",
      "0  13454  9145\n",
      "1    597   657\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | KNeighbors Classifier   #############   Data | all   #############\n",
      "\n",
      "accuracy: 0.6146   precision: 0.05909   recall: 0.42424   f1: 0.10373 \n",
      "\n",
      "       0     1\n",
      "0  14128  8471\n",
      "1    722   532\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | all   #############\n",
      "\n",
      "accuracy: 0.84757   precision: 0.09462   recall: 0.22169   f1: 0.13263 \n",
      "\n",
      "       0     1\n",
      "0  19939  2660\n",
      "1    976   278\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n",
      "#############   Model | Random Forest Classifier Depth 10   #############   Data | all   #############\n",
      "\n",
      "accuracy: 0.91485   precision: 0.08626   recall: 0.06459   f1: 0.07387 \n",
      "\n",
      "       0    1\n",
      "0  21741  858\n",
      "1   1173   81\t\tTraining data resampled from: 67970/3589 to 67970/67970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('KNeighbors Classifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),\n",
    "    ('Decision Tree Classifier Depth 5', DecisionTreeClassifier(max_depth=5)),\n",
    "    ('Random Forest Classifier Depth 10', RandomForestClassifier(max_depth=10,\n",
    "                                                        min_samples_split=20,\n",
    "                                                        min_samples_leaf =20,\n",
    "                                                        max_samples=0.2,\n",
    "                                                        n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "for path in num_paths:\n",
    "    # for resample_size in [67970, 35000]:              # own little search grid\n",
    "    #     for res_method in ['smote_rnd', 'resample']:\n",
    "    pipeline(cats, path, y, models, save_scores=True, sampling='smote_rnd', size=67970)\n",
    "    pipeline(cats, path, y, models, include_cats=False, save_scores=True, sampling='smote_rnd', size=67970)\n",
    "\n",
    "# 22 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############   Model | Decision Tree Classifier Depth 5   #############   Data | var_with_cats   #############\n",
      "\n",
      "DecisionTreeClassifier(max_depth=5)\n",
      "accuracy: 0.84182   precision: 0.07396   recall: 0.19052   f1: 0.10656 \n",
      "\n",
      "       0     1\n",
      "0  19855  2817\n",
      "1    956   225\t\tTraining data resampled from: 67897/3662 to 66666/66666\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeClassifierDepth5_var_with_cats': {'accuracy': 0.84182,\n",
       "  'precision': 0.07396,\n",
       "  'recall': 0.19052,\n",
       "  'f1': 0.10656,\n",
       "  'false_positives': 2817.0,\n",
       "  'true_positives': 225.0,\n",
       "  'resampling': 'smote_rnd'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [('Decision Tree Classifier Depth 5', DecisionTreeClassifier(max_depth=5))]\n",
    "\n",
    "path = 'files_for_lab/var_nums.csv'\n",
    "\n",
    "pipeline(cats, path, y, models, include_cats=True, save_models=True, save_encoder=True, save_scaler=True, save_scores=True, sampling='smote_rnd', size=66666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############   Model | Logistic Regression   #############   Data | var   #############\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy: 0.61929   precision: 0.07169   recall: 0.51618   f1: 0.1259 \n",
      "\n",
      "       0     1\n",
      "0  14118  8468\n",
      "1    613   654\t\tTraining data resampled from: 67983/3576 to 67776/67776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_var': {'accuracy': 0.61929,\n",
       "  'precision': 0.07169,\n",
       "  'recall': 0.51618,\n",
       "  'f1': 0.1259,\n",
       "  'false_positives': 8468.0,\n",
       "  'true_positives': 654.0,\n",
       "  'resampling': 'smote_rnd'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [('Logistic Regression', LogisticRegression())]\n",
    "\n",
    "path = 'files_for_lab/var_nums.csv'\n",
    "\n",
    "pipeline(cats, path, y, models, include_cats=False, save_models=True, save_encoder=True, save_scaler=True, save_scores=True, sampling='smote_rnd', size=67776)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
